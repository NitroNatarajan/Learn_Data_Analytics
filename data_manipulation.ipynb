{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Manipulation and analysis are the key task in any data science or data analyst project. Pandas provides a wide range of function for data manipulation and analysis, making it easier to clean, transform and extract insights from data. Lets see the various data manipulation and analysis techniques using pandas.\n",
    "By using Pandas,we can do exploratory data analysis, perform a lot of feature engineering. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Introduction to Pandas & DataFrames\n",
    "- Install pandas (pip install pandas)\n",
    "- Create Series & DataFrames\n",
    "- Import data from CSV, Excel, JSON, SQL\n",
    "- Explore dataset using df.head(), df.info(), df.describe(), df.shape\n",
    "\n",
    "Indexing & Selecting Data\n",
    "- Indexing methods: ```loc[], iloc[], at[], iat[]```\n",
    "- Column selection: ```df['col'], df[['col1', 'col2']]```\n",
    "- Row selection: ```df.iloc[rows], df.loc[rows]```\n",
    "- Filtering with conditions:``` df[df['col'] > value]```\n",
    "\n",
    "Data Cleaning & Handling Missing Values\n",
    "- Detect missing values: ```df.isnull(), df.notnull()```\n",
    "- Fill missing values:``` df.fillna(value/method='ffill'/'bfill')```\n",
    "- Remove missing values:``` df.dropna()```\n",
    "- Replace values: ```df.replace(old, new)```\n",
    "\n",
    "Data Manipulation & Transformation\n",
    "- Change data types: ```df.astype()```\n",
    "- Rename columns:``` df.rename()```\n",
    "- Apply functions:``` df.apply(), df['col'].map()```\n",
    "- Modify string values:``` .str.lower(), .str.replace(), .str.split()```\n",
    "\n",
    "Data Analysis & Aggregation:\n",
    "\n",
    "Sorting & Filtering Data\n",
    "- Sorting:``` df.sort_values(by='col')```\n",
    "- Filter rows using multiple conditions\n",
    "- Find unique values: ```df.nunique(), df['col'].unique()```\n",
    "\n",
    "Grouping & Aggregation\n",
    "- Grouping with ```df.groupby()```\n",
    "- Aggregation with``` .agg(), .sum(), .mean()```\n",
    "- Pivot tables:``` df.pivot_table()```\n",
    "\n",
    " Merging, Joining & Concatenation\n",
    "- Merge datasets using ```df.merge()```\n",
    "- Concatenate datasets using ```pd.concat()```\n",
    "- Join data using ```df.join()```\n",
    "\n",
    "Time-Series & Performance Optimization:\n",
    "\n",
    "Working with Dates & Time\n",
    "- Convert strings to datetime:``` pd.to_datetime()```\n",
    "- Extract year, month, day:``` df['date'].dt.year```\n",
    "- Time-based filtering: ```df[df['date'] > '2023-01-01']```\n",
    "\n",
    "Advanced Pandas Functions\n",
    "- Reshape data with``` df.melt()```\n",
    "- Explode lists using ```df.explode()```\n",
    "- Use``` df.eval()``` for expressions\n",
    "\n",
    "Performance Optimization\n",
    "- Convert data types for efficiency\n",
    "- Use ```.apply() ```efficiently\n",
    "- Optimize memory usage using``` .astype()```\n",
    "\n",
    "Real-World Applications & Projects:\n",
    "\n",
    "Mini Projects\n",
    "- Project 1: Customer Purchase Analysis\n",
    "- Project 2: Airbnb Price Prediction Dataset\n",
    "- Project 3: Stock Market Data Analysis\n",
    "\n",
    "#### Pick any real-world dataset (Kaggle, UCI)\n",
    "#### Perform full analysis (Cleaning → Transformation → Aggregation → Visualization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date Category  Value   Product  Sales Region\n",
      "0  2023-01-01        A   28.0  Product1  754.0   East\n",
      "1  2023-01-02        B   39.0  Product3  110.0  North\n",
      "2  2023-01-03        C   32.0  Product2  398.0   East\n",
      "3  2023-01-04        B    8.0  Product1  522.0   East\n",
      "4  2023-01-05        B   26.0  Product3  869.0  North\n",
      "          Date Category  Value   Product  Sales Region\n",
      "45  2023-02-15        B   99.0  Product2  599.0   West\n",
      "46  2023-02-16        B    6.0  Product1  938.0  South\n",
      "47  2023-02-17        B   69.0  Product3  143.0   West\n",
      "48  2023-02-18        C   65.0  Product3  182.0  North\n",
      "49  2023-02-19        C   11.0  Product3  708.0  North\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50 entries, 0 to 49\n",
      "Data columns (total 6 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   Date      50 non-null     object \n",
      " 1   Category  50 non-null     object \n",
      " 2   Value     47 non-null     float64\n",
      " 3   Product   50 non-null     object \n",
      " 4   Sales     46 non-null     float64\n",
      " 5   Region    50 non-null     object \n",
      "dtypes: float64(2), object(4)\n",
      "memory usage: 2.5+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(50, 6)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ========================Data Manipulation with Numpy and Pandas============================== \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Lets dive in with the sample dataset, perform analysis, eda, handling missing values and others..\n",
    "\n",
    "df = pd.read_csv(\"data_set/data.csv\")\n",
    "\n",
    "print(df.head()) # return first 5 rows \n",
    "print(df.tail()) # return last 5 rows\n",
    "df.info() # There are 50 records and found the sales and values have null values in their column \n",
    "df.describe() # return the basic stats about the data frame for the numerical columns \n",
    "# but not the categorical columns are considered\n",
    "df.dtypes\n",
    "df.columns\n",
    "df.index\n",
    "df.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "####  Indexing & Selecting Data:\n",
    "  - Indexing methods: ``` loc[], iloc[], at[], iat[]```\n",
    "  - Column selection: ``` df['col'], df[['col1', 'col2']]```\n",
    "  - Row selection: ``` df.iloc[rows], df.loc[rows]```\n",
    "  - Filtering with conditions: ``` df[df['col'] > value]```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Category</th>\n",
       "      <th>Value</th>\n",
       "      <th>Product</th>\n",
       "      <th>Sales</th>\n",
       "      <th>Region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-01-03</td>\n",
       "      <td>C</td>\n",
       "      <td>32.0</td>\n",
       "      <td>Product2</td>\n",
       "      <td>398.0</td>\n",
       "      <td>East</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2023-01-08</td>\n",
       "      <td>C</td>\n",
       "      <td>89.0</td>\n",
       "      <td>Product1</td>\n",
       "      <td>488.0</td>\n",
       "      <td>West</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2023-01-14</td>\n",
       "      <td>A</td>\n",
       "      <td>69.0</td>\n",
       "      <td>Product1</td>\n",
       "      <td>423.0</td>\n",
       "      <td>East</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2023-01-24</td>\n",
       "      <td>C</td>\n",
       "      <td>92.0</td>\n",
       "      <td>Product2</td>\n",
       "      <td>342.0</td>\n",
       "      <td>West</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2023-01-25</td>\n",
       "      <td>A</td>\n",
       "      <td>24.0</td>\n",
       "      <td>Product2</td>\n",
       "      <td>458.0</td>\n",
       "      <td>East</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2023-01-28</td>\n",
       "      <td>C</td>\n",
       "      <td>56.0</td>\n",
       "      <td>Product2</td>\n",
       "      <td>224.0</td>\n",
       "      <td>North</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2023-02-02</td>\n",
       "      <td>B</td>\n",
       "      <td>63.0</td>\n",
       "      <td>Product3</td>\n",
       "      <td>338.0</td>\n",
       "      <td>South</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2023-02-08</td>\n",
       "      <td>C</td>\n",
       "      <td>94.0</td>\n",
       "      <td>Product1</td>\n",
       "      <td>408.0</td>\n",
       "      <td>South</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>2023-02-11</td>\n",
       "      <td>C</td>\n",
       "      <td>97.0</td>\n",
       "      <td>Product1</td>\n",
       "      <td>256.0</td>\n",
       "      <td>East</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date Category  Value   Product  Sales Region\n",
       "2   2023-01-03        C   32.0  Product2  398.0   East\n",
       "7   2023-01-08        C   89.0  Product1  488.0   West\n",
       "13  2023-01-14        A   69.0  Product1  423.0   East\n",
       "23  2023-01-24        C   92.0  Product2  342.0   West\n",
       "24  2023-01-25        A   24.0  Product2  458.0   East\n",
       "27  2023-01-28        C   56.0  Product2  224.0  North\n",
       "32  2023-02-02        B   63.0  Product3  338.0  South\n",
       "38  2023-02-08        C   94.0  Product1  408.0  South\n",
       "41  2023-02-11        C   97.0  Product1  256.0   East"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Indexing Methods\n",
    "# DataFrame.at : Access a single value for a row/column pair by label and/or set an value to that position\n",
    "# DataFrame.iat : Access a single value for a row/column pair by integer position and/or set an value to that integer position\n",
    "# DataFrame.loc : Access a group of rows and columns by label(s).\n",
    "# DataFrame.iloc : Access a group of rows and columns by integer position(s).\n",
    "\n",
    "df.loc[2,\"Sales\"]\n",
    "df.loc[0]\n",
    "df.loc[df[\"Category\"]== \"A\"]\n",
    "df.loc[(df[\"Category\"]== \"A\") & (df[\"Sales\"] > 200)]\n",
    "\n",
    "df.iloc[0,1]\n",
    "df.iloc[[0,1,2,4,5,6,7]]\n",
    "df.iloc[1:7, 2:]\n",
    "df.iloc[[0,1],[2,3]]\n",
    "\n",
    "df.at[0 , \"Sales\"]\n",
    "df.at[0 , \"Sales\"] = 755\n",
    "df.at[0 , \"Sales\"]\n",
    "df.loc[2].at[\"Value\"] \n",
    "\n",
    "df.iat[1,5]\n",
    "df.iat[1,5] = \"South\"\n",
    "df.iat[1,5]\n",
    "df.loc[1].iat[5] \n",
    "\n",
    "# Column Selection \n",
    "\n",
    "df[\"Category\"] # any single column by their column name\n",
    "df[[\"Category\", \"Sales\", \"Sales\",\"Value\"]] # select any no of column and retrieve it in any order as we need\n",
    "\n",
    "# Row Selection \n",
    "df.loc[2:5,:]\n",
    "df.loc[:7,:]\n",
    "df.loc[0:5, \"Sales\"]\n",
    "\n",
    "df.iloc[0:5,:]\n",
    "df.iloc[:,4:]\n",
    "\n",
    "# Filtering with condition \n",
    "df.loc[df[\"Sales\"]>500]\n",
    "df[(df[\"Category\"]==\"A\") | (df[\"Category\"]==\"B\") ]\n",
    "df[(df[\"Sales\"]>200) & (df[\"Sales\"]<500) ]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling Missing Values:\n",
    "# Data Cleaning & Handling Missing Values\n",
    "# - Detect missing values: ```df.isnull(), df.notnull()```\n",
    "# - Fill missing values:``` df.fillna(value/method='ffill'/'bfill')```\n",
    "# - Remove missing values:``` df.dropna()```\n",
    "# - Replace values: ```df.replace(old, new)```\n",
    "\n",
    "\n",
    "# When the dataset get loaded, we generally check the Shape,structure and columns, head and tail, dtypes, \n",
    "# and total entries, dtypes, null values if any. \n",
    "\n",
    "# To see how many missing values exist in each column:\n",
    "df.isnull() # return the Dataframe with true and False values on each index\n",
    "df.isnull().sum() # return the sum of each columns null Values \n",
    "\n",
    "# To see how many non-missing values exist in each column:\n",
    "df.notnull() # return the Dataframe with true and False filled on each index, True means values not null, False for null values\n",
    "df.notnull().sum() # Return the count of not null for each column \n",
    "# it gives the count of non missing values in each column if any exist\n",
    "# This way we can detect the missing values easily and guess how many null values in each columns\n",
    "\n",
    "#  Find Rows That Contain Missing Values \n",
    "df.isnull().any(axis=1).sum() # No of rows in total have the null/missing values\n",
    "df[df.isnull().any(axis=1)] # All the rows which have at least one null/missing value\n",
    "df.isnull().any() # Which return the column which has missing values \n",
    "# Find Rows Where a Specific Column Has Missing Values\n",
    "df[df[\"Sales\"].isnull()]\n",
    "df[df[\"Value\"].isnull()]\n",
    "\n",
    "#  Get the Percentage of Missing Data in Each Column\n",
    "(df.isnull().sum()/len(df))*100\n",
    "\n",
    "\n",
    "# Filling missing values:\n",
    "# df.fillna(value/method='ffill'/'bfill')\n",
    "\n",
    "df1 = df.fillna(0) # All the missing values will be replaced with zero \n",
    "# In general it is temporary, it doesn't persistent, so we must save it a variable to get the filled Dataframe and work on it\n",
    "df1.isnull().sum() # No missing valaues now.\n",
    "# Commonly, we don't usually fill with zero's, probably it depends on the values distribution and/or mean of the whole column \n",
    "\n",
    "# Filling missing values with mean of the column \n",
    "\n",
    "# df[\"Sales\"].mean() # it gives the mean of that column \n",
    "df[\"Sales_fillNA\"] = df[\"Sales\"].fillna(df[\"Sales\"].mean()) \n",
    "# Above, we fill the Sales column missing values with mean of that column and named it as Sales_fillNA\n",
    "df[\"Sales_ffill\"] = df[\"Sales\"].bfill() # the missing value replaced with the value at the previous row\n",
    "df[\"Sales_bfill\"] = df[\"Sales\"].ffill() # the missing value replaced with the value in the next row \n",
    "\n",
    "\n",
    "# Remove Missing Values\n",
    "df3 = pd.read_csv(\"data_set/data.csv\")\n",
    "\n",
    "df3.isnull().sum() \n",
    "# sales has 4 missing values, Value has 3 missing values\n",
    "\n",
    "x = df3.dropna() # this takes parameter such as axis,how:any | all, thresh,subset,inplace:True|False,ignore_index:True|False\n",
    "# Drop the rows where at least one element is missing.\n",
    "\n",
    "x.isnull().sum() \n",
    "# it shows that all the null valued row are dropped\n",
    "\n",
    "\n",
    "# - Replace values: df.replace(old, new)\n",
    "df4 = pd.DataFrame({\n",
    "  \"Name\":[\"Natarajan\",\"Karikalan\",\"Athistalakshmi\",\"Nitro\",\"Leela\"],\n",
    "  \"Age\":[32,30,22,28,55],\n",
    "  \"Location\":[\"Trichy\",\"Thirunelveli\",\"Thirupathi\",\"Ariyalur\",\"Vilagam\"]\n",
    "})\n",
    "df4.replace(30,32) # it would replace all the 30 data into 32 irrespective any row or column\n",
    "df4.replace([32,22,55],25) # it would replace all the 32,22,55 to 25 \n",
    "df4.replace(\"Natarajan\",\"Natraj\") # Natarajan becomes Natraj\n",
    "df4.replace([32,30,22,28,55],[11,22,33,44,55])\n",
    "df4.replace({\"Trichy\":\"Thiruchirapalli\",\"Thirupathi\":\"Palani\"})\n",
    "df4.replace({32:30,22:30,55:30}) \n",
    "df4.replace({\"Age\":{0:40,4:55},\"Location\":{\"Ariyalur\":\"Ariyalurr\",\"Vilagam\":\"Valaagam\"}})\n",
    "\n",
    "df.isnull().sum()\n",
    "df[df.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets focus on changing the dtype of some column like date column object dtype to date. \n",
    "# Later we will see while EDA, we will see how to change the dtype of date column from object dtype to date column. \n",
    "\n",
    "# Data Manipulation & Transformation\n",
    "# - Change data types: ```df.astype()```\n",
    "# - Rename columns:``` df.rename()```\n",
    "# - Apply functions:``` df.apply(), df['col'].map()```\n",
    "# - Modify string values:``` .str.lower(), .str.replace(), .str.split()```\n",
    "\n",
    "# Change the datatype:\n",
    "# To change the dtype of the date from object column to date column, we may use the df.astype()\n",
    "# eg: on sales column, the dtype is float64, wanna cast to float32\n",
    "df[\"Value_new\"] = df[\"Value\"].fillna(df[\"Value\"].mean()).astype(\"int32\")\n",
    "\n",
    "\n",
    "# RENAME Columns\n",
    "# To rename a column we can use the rename method on dataframe \n",
    "# here the column parameter is used columns:{\"MAPPER\":\"rename column\"}\n",
    "df.rename(columns={\"Date\":\"Sales_Date\"}) \n",
    "\n",
    "# lets say i wanna apply a function to a column eg: value got raised by 10% \n",
    "df[\"Revised_value\"] = ((df[\"Value\"].fillna(df[\"Sales\"].mean()))*1.1).astype(\"int32\")\n",
    "\n",
    "# here we can apply function on the column values to manipulate the column, we can pass the lambda or inbuilt function \n",
    "df[\"Double_value\"] = df[\"Value_new\"].apply(lambda x:x*2)\n",
    "\n",
    "df[\"Sales_drop_to\"] = df[\"Sales_fillNA\"].map(lambda x:x*0.9)\n",
    "df5 = df.rename(columns={\"double_scaled_value\":\"Double_Value\",\"sales_depreciation_by_10\":\"Sales_drop_to\",\"Revised_value\":\"Re_value\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>values_x</th>\n",
       "      <th>values_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>E</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  key  values_x  values_y\n",
       "0   A       1.0         4\n",
       "1   B       2.0         5\n",
       "2   C       3.0         6\n",
       "3   E       NaN         7"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data Aggregation and Data Grouping\n",
    "# Grouping & Aggregation\n",
    "# - Grouping with ```df.groupby()```\n",
    "# - Aggregation with``` .agg(), .sum(), .mean()```\n",
    "# - Pivot tables:``` df.pivot_table()```\n",
    "# Grouping the data \n",
    "# LETS GROUP THE DATA BY CATEGORY \n",
    "\n",
    "df5.groupby(\"Category\")[\"Value\"].mean()\n",
    "df5.groupby(\"Product\")[\"Value\"].mean()\n",
    "\n",
    "# grouping by more than one column \n",
    "grouped_sum = df5.groupby([\"Product\",\"Category\"])[\"Sales_fillNA\"].sum()\n",
    "grouped_mean = df5.groupby([\"Product\",\"Category\"])[\"Sales_fillNA\"].mean()\n",
    "\n",
    "# Multiple aggregate functions on multiple values grouped by region:\n",
    "grouped_agg = df5.groupby(\"Region\")[[\"Sales_fillNA\",\"Value_new\"]].agg([\"mean\",\"sum\",\"count\"])\n",
    "\n",
    "# pivot table\n",
    "\n",
    "\n",
    "#  Merging, Joining & Concatenation\n",
    "# - Merge datasets using ```df.merge()```\n",
    "# - Concatenate datasets using ```pd.concat()```\n",
    "# - Join data using ```df.join()```\n",
    "\n",
    "\n",
    "# Merging and joining and concatenating Dataframes\n",
    "# create a sample dataframe\n",
    "df1 = pd.DataFrame({\"key\":[\"A\",\"B\",\"C\",\"D\"],\"values\":[1,2,3,4]})\n",
    "df2 = pd.DataFrame({\"key\":[\"A\",\"B\",\"C\",\"E\"],\"values\":[4,5,6,7]})\n",
    "\n",
    "# merge the dta frames on the key columns =>mean the join \n",
    "pd.merge(df1,df2,on=\"key\", how=\"inner\")\n",
    "pd.merge(df1,df2,on=\"key\", how=\"outer\")\n",
    "pd.merge(df1,df2,on=\"key\", how=\"left\")\n",
    "pd.merge(df1,df2,on=\"key\", how=\"right\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
