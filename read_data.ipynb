{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading Data from Different Resources\n",
    "- lets learn how do we read data from different resources using available in-built function in pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[{\"employee_name\":\"James\",\"email\":\"james@gmail.com\",\"job_profile\":{\"title1\":\"Team Lead\",\"title2\":\"Sr.Developer\"}}]'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from io import StringIO\n",
    "data = '{\"employee_name\": \"James\",\"email\": \"james@gmail.com\", \"job_profile\":[{\"title1\":\"Team Lead\",\"title2\":\"Sr.Developer\"}]}'\n",
    "\n",
    "# we have json object in the data..lets learn how to load this json into pandas and create a data frame.\n",
    "\n",
    "# if we have a json data,by this way we can able to convert it into a dataframe. \n",
    "df = pd.read_json(StringIO(data))\n",
    "df.to_json(orient=\"index\") \n",
    "# As soon as we execute this line of code, the given dataframe convert the dataframe into the json string object.\n",
    "# But it looks different than source for the dataframe creation.\n",
    "df.to_json(orient='records')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install lxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have a data in the url html page as a comma separated file. lets load that now\n",
    "url = \"https://gist.githubusercontent.com/tijptjik/9408623/raw/b237fa5848349a14a14e5d4107dc7897c21951f5/wine.csv\"\n",
    "df = pd.read_csv(url, header=None)\n",
    "df.to_csv(\"./data_set/wine.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets say we have html which have a table data that can be scrapped by the pandas function. \n",
    "url = \"https://www.fdic.gov/bank-failures/failed-bank-list?combine=&items_per_page=All\"\n",
    "df = pd.read_html(url, match=\"Acquiring Institution\")\n",
    "df[0].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets try with some wikipedia site where we find a table and scrap it up. \n",
    "url=\"https://en.wikipedia.org/wiki/List_of_states_and_union_territories_of_India_by_population\"\n",
    "df = pd.read_html(url, match=\"Rank\",header=None)\n",
    "df[0].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"https://en.wikipedia.org/wiki/Mobile_country_code\"\n",
    "df = pd.read_html(url, match=\"Country\", header=None)\n",
    "df[0]\n",
    "\n",
    "# This is how we can able to scrap the entire table in the html. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the xlsx file and create a dataframe\n",
    "df = pd.read_excel(\"data_set/excel_file.xlsx\")\n",
    "display(df)\n",
    "# This way we can read the xlsx file easily by the pandas function.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pickle File :\n",
    "  - A pickle file in Python is a file format used for serializing and deserializing Python object structures. The process of converting a Python object into a byte stream is called \"pickling,\" while the reverse process of recreating the object from the byte stream is called \"unpickling.\" This mechanism is similar to object serialization in other programming languages like Java. The pickle module is particularly useful for saving and loading complex data structures like lists, dictionaries, and even custom class instances.\n",
    "  \n",
    "  - Pickle files are binary files, and they are specific to Python. This means that data pickled in Python can only be reliably unpickled using Python. While this can be a limitation for cross-language compatibility, it makes pickle very efficient for storing and retrieving Python objects within Python applications.\n",
    "  \n",
    "  - It's important to note that the pickle module is not secure against maliciously constructed data. Unpickling data from untrusted sources can lead to arbitrary code execution. Therefore, it's crucial to only unpickle data that comes from a trusted source. If data integrity and security are paramount, consider using safer serialization formats like JSON, especially when dealing with external or untrusted data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here i have been converting the dataframe objects into pickle file. df contains the dataframe.\n",
    "excel_df = pd.read_excel(\"data_set/excel_file.xlsx\")\n",
    "excel_df.to_pickle(\"data_set/df_excel_pickle\")\n",
    "\n",
    "# the pickle files are serialized, so we can't open up th file without un-pickling the file \n",
    "# to unpickle the file, we must use the read_pickle method \n",
    "unpickled_file = pd.read_pickle(\"./data_set/df_excel_pickle\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
